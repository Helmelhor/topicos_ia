# Agente de IA para Super Mario Bros com Aprendizado por Refor√ßo

[cite\_start]Este projeto desenvolve um agente de intelig√™ncia artificial capaz de aprender a jogar o cl√°ssico Super Mario Bros. do zero, utilizando t√©cnicas de Aprendizado por Refor√ßo (Reinforcement Learning). [cite: 3] [cite\_start]O objetivo final √© treinar um modelo que consiga avan√ßar o m√°ximo poss√≠vel nas fases do jogo, maximizando sua pontua√ß√£o e evitando obst√°culos de forma aut√¥noma. [cite: 5]

[cite\_start]O agente aprende por tentativa e erro, interagindo com o ambiente do jogo e recebendo "recompensas" por a√ß√µes bem-sucedidas, como avan√ßar para a direita, e "puni√ß√µes" por a√ß√µes ruins, como morrer. [cite: 4, 14]

## üß† Conceitos Fundamentais

O projeto √© baseado nos seguintes conceitos de Aprendizado por Refor√ßo:

  * **Agente**: O nosso "rob√¥" ou c√©rebro, que √© uma Rede Neural Convolucional (CNN) respons√°vel por tomar as decis√µes (a√ß√µes) dentro do jogo. 
  * **Ambiente**: O pr√≥prio jogo Super Mario Bros emulado, com suas regras, fases e inimigos. O ambiente fornece ao agente o estado atual da tela e uma recompensa ap√≥s cada a√ß√£o. 
  * **Estado**: Uma "fotografia" da tela do jogo em um determinado momento, representada pelos pixels da imagem. Para dar ao agente a no√ß√£o de movimento, n√≥s empilhamos 4 frames consecutivos como um √∫nico estado.
  * **A√ß√µes**: As decis√µes que o agente pode tomar, como andar para a direita, pular ou correr. Para simplificar, utilizamos um conjunto reduzido de 7 a√ß√µes essenciais. 
  * **Recompensa**: Um sinal num√©rico que o ambiente envia ao agente. A recompensa padr√£o premia o avan√ßo para a direita, penaliza o tempo e a morte do personagem. 

## üõ†Ô∏è Tecnologias e Bibliotecas

Este projeto foi constru√≠do utilizando Python 3.7 e um conjunto espec√≠fico de bibliotecas para garantir a compatibilidade.

  * [cite\_start]**Stable-Baselines3 (v1.8.0)**: O framework de alto n√≠vel que cont√©m a implementa√ß√£o do algoritmo de aprendizado **PPO (Proximal Policy Optimization)**. [cite: 25, 36]
  * **Gym (v0.21.0)**: O "gin√°sio" que fornece a interface padr√£o para comunica√ß√£o entre o agente e o ambiente.
  * [cite\_start]**gym-super-mario-bros**: A biblioteca que encapsula o emulador do Super Mario Bros como um ambiente Gym. [cite: 37]
  * **NumPy (v1.21.6)**: Biblioteca fundamental para todos os c√°lculos num√©ricos e manipula√ß√£o dos frames do jogo.
  * [cite\_start]**OpenCV-Python**: Utilizada para o pr√©-processamento das imagens (redimensionamento e convers√£o para tons de cinza). [cite: 38]
  * **TensorBoard**: Ferramenta para visualizar as m√©tricas e o progresso do treinamento em tempo real.

## üöÄ Como Executar o Projeto

Para replicar este projeto, siga os passos abaixo.

### 1\. Pr√©-requisitos

  * **Anaconda (ou Miniconda)** instalado para gerenciar o ambiente virtual.
  * **Python 3.7**.
  * [cite\_start]**Visual Studio (Community Edition)** com a carga de trabalho "Desenvolvimento para desktop com C++" (necess√°rio no Windows para compilar uma das depend√™ncias). [cite: 39]

### 2\. Configura√ß√£o do Ambiente

Primeiro, crie um ambiente virtual e instale todas as depend√™ncias a partir do arquivo `requirements.txt`.

```bash
# Crie e ative um novo ambiente com Python 3.7
conda create -n mario-ia python=3.7
conda activate mario-ia

# Instale todas as bibliotecas necess√°rias de uma vez
pip install -r requirements.txt
```

**Conte√∫do do arquivo `requirements.txt`:**

```
# Framework de Aprendizado por Refor√ßo (vers√£o antiga e est√°vel)
stable-baselines3==1.8.0

# Padr√£o de ambiente de treinamento (vers√£o cl√°ssica)
gym==0.21.0

# Biblioteca para o ambiente do jogo Super Mario Bros
gym-super-mario-bros

# Processamento de imagem (usado pelos wrappers)
opencv-python

# C√°lculos num√©ricos (vers√£o compat√≠vel com Python 3.7 e a pilha acima)
numpy==1.21.6

# Depend√™ncia do Gym 0.21.0 para gerenciamento de plugins
importlib-metadata==4.13.0

# Para visualiza√ß√£o e monitoramento do treinamento
tensorboard

# Ambiente de desenvolvimento interativo
jupyter
```

### 3\. Treinando o Agente

Para iniciar um novo treinamento, execute o script `treinamento.py`. O progresso ser√° salvo periodicamente na pasta `./train/`.

```bash
python treinamento.py
```

### 4\. Testando o Agente

Para assistir a um agente j√° treinado jogando, execute o script `teste.py`. Lembre-se de alterar o nome do arquivo `.zip` dentro do script para carregar o modelo desejado.

```bash
python teste.py
```
